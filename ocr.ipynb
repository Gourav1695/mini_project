{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# initialize the base path to the input documents dataset\n",
    "BASE_PATH = \"C:\\Programmes\\python\\mini_project\"\n",
    "# define the path to the training directories\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"train\"])\n",
    "CLEANED_PATH = os.path.sep.join([BASE_PATH, \"train_cleaned\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def blur_and_threshold(image, eps=1e-7):\n",
    "\t# apply a median blur to the image and then subtract the blurred\n",
    "\t# image from the original image to approximate the foreground\n",
    "\tblur = cv2.medianBlur(image, 5)\n",
    "\tforeground = image.astype(\"float\") - blur\n",
    "\t# threshold the foreground image by setting any pixels with a\n",
    "\t# value greater than zero to zero\n",
    "\tforeground[foreground > 0] = 0\n",
    "    # apply min/max scaling to bring the pixel intensities to the\n",
    "\t# range [0, 1]\n",
    "\tminVal = np.min(foreground)\n",
    "\tmaxVal = np.max(foreground)\n",
    "\tforeground = (foreground - minVal) / (maxVal - minVal + eps)\n",
    "\t# return the foreground-approximated image\n",
    "\treturn foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from config import denoise_config as config\n",
    "from pyimagesearch.denoising import blur_and_threshold\n",
    "from imutils import paths\n",
    "import progressbar\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPaths = sorted(list(paths.list_images(config.TRAIN_PATH)))\n",
    "cleanedPaths = sorted(list(paths.list_images(config.CLEANED_PATH)))\n",
    "# initialize the progress bar\n",
    "widgets = [\"Creating Features: \", progressbar.Percentage(), \" \",\n",
    "\tprogressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(trainPaths),\n",
    "\twidgets=widgets).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = zip(trainPaths, cleanedPaths)\n",
    "csv = open(config.FEATURES_PATH, \"w\")\n",
    "# loop over the training images together\n",
    "for (i, (trainPath, cleanedPath)) in enumerate(imagePaths):\n",
    "\t# load the noisy and corresponding gold-standard cleaned images\n",
    "\t# and convert them to grayscale\n",
    "\ttrainImage = cv2.imread(trainPath)\n",
    "\tcleanImage = cv2.imread(cleanedPath)\n",
    "\ttrainImage = cv2.cvtColor(trainImage, cv2.COLOR_BGR2GRAY)\n",
    "\tcleanImage = cv2.cvtColor(cleanImage, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImage = cv2.copyMakeBorder(trainImage, 2, 2, 2, 2,\n",
    "\t\tcv2.BORDER_REPLICATE)\n",
    "\tcleanImage = cv2.copyMakeBorder(cleanImage, 2, 2, 2, 2,\n",
    "\t\tcv2.BORDER_REPLICATE)\n",
    "\t# blur and threshold the noisy image\n",
    "\ttrainImage = blur_and_threshold(trainImage)\n",
    "\t# scale the pixel intensities in the cleaned image from the range\n",
    "\t# [0, 255] to [0, 1] (the noisy image is already in the range\n",
    "\t# [0, 1])\n",
    "\tcleanImage = cleanImage.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(0, trainImage.shape[0]):\n",
    "\t\tfor x in range(0, trainImage.shape[1]):\n",
    "\t\t\t# extract the window ROIs for both the train image and\n",
    "\t\t\t# clean image, then grab the spatial dimensions of the\n",
    "\t\t\t# ROI\n",
    "\t\t\ttrainROI = trainImage[y:y + 5, x:x + 5]\n",
    "\t\t\tcleanROI = cleanImage[y:y + 5, x:x + 5]\n",
    "\t\t\t(rH, rW) = trainROI.shape[:2]\n",
    "\t\t\t# if the ROI is not 5x5, throw it out\n",
    "\t\t\tif rW != 5 or rH != 5:\n",
    "\t\t\t\tcontinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trainROI.flatten()\n",
    "\t\t\ttarget = cleanROI[2, 2]\n",
    "\t\t\t# if we wrote *every* feature/target combination to disk\n",
    "\t\t\t# we would end up with millions of rows -- let's only\n",
    "\t\t\t# write rows to disk with probability N, thereby reducing\n",
    "\t\t\t# the total number of rows in the file\n",
    "\t\t\tif random.random() <= config.SAMPLE_PROB:\n",
    "\t\t\t\t# write the target and features to our CSV file\n",
    "\t\t\t\tfeatures = [str(x) for x in features]\n",
    "\t\t\t\trow = [str(target)] + features\n",
    "\t\t\t\trow = \",\".join(row)\n",
    "\t\t\t\tcsv.write(\"{}\\n\".format(row))\n",
    "\t# update the progress bar\n",
    "\tpbar.update(i)\n",
    "# close the CSV file\n",
    "pbar.finish()\n",
    "csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import denoise_config as config\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading dataset...\")\n",
    "features = []\n",
    "targets = []\n",
    "# loop over the rows in our features CSV file\n",
    "for row in open(config.FEATURES_PATH):\n",
    "\t# parse the row and extract (1) the target pixel value to predict\n",
    "\t# along with (2) the 5x5=25 pixels which will serve as our feature\n",
    "\t# vector\n",
    "\trow = row.strip().split(\",\")\n",
    "\trow = [float(x) for x in row]\n",
    "\ttarget = row[0]\n",
    "\tpixels = row[1:]\n",
    "\t# update our features and targets lists, respectively\n",
    "\tfeatures.append(pixels)\n",
    "\ttargets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the features and targets to NumPy arrays\n",
    "features = np.array(features, dtype=\"float\")\n",
    "target = np.array(targets, dtype=\"float\")\n",
    "# construct our training and testing split, using 75% of the data for\n",
    "# training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, target,\n",
    "\ttest_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] training model...\")\n",
    "model = RandomForestRegressor(n_estimators=10)\n",
    "model.fit(trainX, trainY)\n",
    "# compute the root mean squared error on the testing set\n",
    "print(\"[INFO] evaluating model...\")\n",
    "preds = model.predict(testX)\n",
    "rmse = np.sqrt(mean_squared_error(testY, preds))\n",
    "print(\"[INFO] rmse: {}\".format(rmse))\n",
    "# serialize our random forest regressor to disk\n",
    "f = open(config.MODEL_PATH, \"wb\")\n",
    "f.write(pickle.dumps(model))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import argparse\n",
    "import pickle\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-t\", \"--testing\", required=True,\n",
    "\thelp=\"path to directory of testing images\")\n",
    "ap.add_argument(\"-s\", \"--sample\", type=int, default=10,\n",
    "\thelp=\"sample size for testing images\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.loads(open(config.MODEL_PATH, \"rb\").read())\n",
    "# grab the paths to all images in the testing directory and then\n",
    "# randomly sample them\n",
    "imagePaths = list(paths.list_images(args[\"testing\"]))\n",
    "random.shuffle(imagePaths)\n",
    "imagePaths = imagePaths[:args[\"sample\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "\t# load the image, convert it to grayscale, and clone it\n",
    "\tprint(\"[INFO] processing {}\".format(imagePath))\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\torig = image.copy()\n",
    "\t# pad the image followed by blurring/thresholding it\n",
    "\timage = cv2.copyMakeBorder(image, 2, 2, 2, 2,\n",
    "\t\tcv2.BORDER_REPLICATE)\n",
    "\timage = blur_and_threshold(image)\n",
    "\troiFeatures = []\n",
    "\t# slide a 5x5 window across the image\n",
    "\tfor y in range(0, image.shape[0]):\n",
    "\t\tfor x in range(0, image.shape[1]):\n",
    "\t\t\t# extract the window ROI and grab the spatial dimensions\n",
    "\t\t\troi = image[y:y + 5, x:x + 5]\n",
    "\t\t\t(rH, rW) = roi.shape[:2]\n",
    "\t\t\t# if the ROI is not 5x5, throw it out\n",
    "\t\t\tif rW != 5 or rH != 5:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# our features will be the flattened 5x5=25 pixels from\n",
    "\t\t\t# the training ROI\n",
    "\t\t\tfeatures = roi.flatten()\n",
    "\t\t\troiFeatures.append(features)\n",
    "\tpixels = model.predict(roiFeatures)\n",
    "\t# the pixels list is currently a 1D array so we need to reshape\n",
    "\t# it to a 2D array (based on the original input image dimensions)\n",
    "\t# and then scale the pixels from the range [0, 1] to [0, 255]\n",
    "\tpixels = pixels.reshape(orig.shape)\n",
    "\toutput = (pixels * 255).astype(\"uint8\")\n",
    "\t# show the original and output images\n",
    "\tcv2.imshow(\"Original\", orig)\n",
    "\tcv2.imshow(\"Output\", output)\n",
    "\tcv2.waitKey(0)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b2aaf87f9d392dc0e4254d9df0dd17bd7d2f65f41d88b63290e5fbe92909be5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
